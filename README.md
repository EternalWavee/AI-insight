# AI-Insight——Whisper + KeyBERT Pipeline Demo

## 初版想法
- 使用 **Whisper-X** 进行 ASR，将语音转为文本。
- 同时采样音频特征（如能量、频率等）。
- 将文本和音频特征对齐，训练一个简单的网络（如 MLP）进行关键词打分。
- 最终生成可视化，如词云或高亮文本。

### 限制
- 个人电脑性能有限，无法训练大型模型。
- 实验室 GPU 网络受限，下载大型预训练模型困难。

## 最终实现
- 使用 **Whisper small** 完成 ASR 转写。
- 利用 **预训练 KeyBERT** 进行关键词提取（牺牲了声学信息，但非常省算力）。
- 生成 **词云** 可视化关键词。
- 打通 **完整 Pipeline**，从音频到前端 JSON + 词云一键完成。

## Pipeline 特点
1. **一条命令执行**：输入音频即可得到整合 JSON 和词云。
2. **整合 JSON**：包含 ASR 原文、Token 特征、关键词信息，前端可直接使用。
3. **可视化**：生成关键词词云，同时可标注每个词的 TF-IDF、词性、频率等。

## Future Work
- 使用更强计算资源训练自定义关键词预测模型，结合声学信息。
- 尝试自动排版和高级可视化，而不仅仅是词云。
- 支持 **流式处理**，类似 Transformer-Transducer（T-T），实时返回识别与关键词结果。
- 增加多模态信息融合，比如情感分析、语音音色特征等。（真的很吃算力 我这个电脑太差了）

## 前端演示说明（可选）
- 使用生成的 `frontend_data.json` 文件作为前端数据源。
- 可以高亮关键词，显示每个 token 的词性、TF-IDF 和频率。
- 词云可直接显示 top N 关键词及其权重。
- 可配合简单的 HTML/JS 或 React 实现动态展示。


##后续工作
- 打算用MLP/transformer 训练一个新的key word分类器
- 并且打算利用对齐audio的信息，比如energy用来代表重音，可以更好的预测keyword
- 可以顺便使用其他model把文本直接输出大纲，辅以词云应该会更好